# -*- coding: utf-8 -*-
"""Implementation of Decision Tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cPGggMPcnF626KK85WItf2TxzTA32EZT

**Importing Libraries**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""**Loading Dataset**"""

dataframe = pd.read_csv('/content/WineQT.csv')

dataframe.head(30)

"""**Checking Rows and Columns of Dataset**"""

dataframe.shape

dataframe.describe()

dataframe['quality'].unique()

dataframe['quality'].value_counts()

dataframe.dtypes

dataframe.isnull().sum()

"""**Corelation **"""

dataframe.corr()

"""**Heatmap of coefficient corelation**"""

plt.figure(figsize=(15,15))
sns.heatmap(dataframe.corr(),annot=True)
plt.savefig('heatmap.jpg')
plt.show()

dataframe.columns

"""**Data Imputation**

1.   Data is symmetrical --> Mean
2.   Data is non - symmetric --> Median


"""

sns.distplot(dataframe['alcohol'])

dataframe['alcohol'] = dataframe['alcohol'].replace(0,dataframe['alcohol'].mean())
sns.distplot(dataframe['alcohol'])

sns.distplot(dataframe['sulphates'])

dataframe['sulphates'] = dataframe['sulphates'].replace(0,dataframe['sulphates'].mean())
sns.distplot(dataframe['sulphates'])

sns.distplot(dataframe['pH'])

dataframe['pH'] = dataframe['pH'].replace(0,dataframe['pH'].mean())
sns.distplot(dataframe['pH'])

sns.distplot(dataframe['density'])

dataframe['density'] = dataframe['density'].replace(0,dataframe['density'].mean())
sns.distplot(dataframe['density'])

sns.distplot(dataframe['total sulfur dioxide'])

dataframe['total sulfur dioxide'] = dataframe['total sulfur dioxide'].replace(0,dataframe['total sulfur dioxide'].median())
sns.distplot(dataframe['total sulfur dioxide'])

sns.distplot(dataframe['free sulfur dioxide'])

dataframe['free sulfur dioxide'] = dataframe['free sulfur dioxide'].replace(0,dataframe['free sulfur dioxide'].median())
sns.distplot(dataframe['free sulfur dioxide'])

sns.distplot(dataframe['chlorides'])

dataframe['chlorides'] = dataframe['chlorides'].replace(0,dataframe['chlorides'].median())
sns.distplot(dataframe['chlorides'])

sns.distplot(dataframe['residual sugar'])

dataframe['residual sugar'] = dataframe['residual sugar'].replace(0,dataframe['residual sugar'].median())
sns.histplot(dataframe['residual sugar'],kde=True)

sns.distplot(dataframe['citric acid'])

dataframe['citric acid'] = dataframe['citric acid'].replace(0,dataframe['citric acid'].median())

sns.distplot(dataframe['volatile acidity'])

sns.distplot(dataframe['fixed acidity'])

"""**Segregating Dependent and Independent feature**


1.   x = dependent feature
2.   y = independent feature


"""

x = dataframe.drop(['quality'],axis=1)
y = dataframe['quality']

"""**Plotting Outlier**"""

fig, ax = plt.subplots(figsize=(15,15))
plt.xticks(rotation=90)
sns.boxplot(data = x, ax = ax)
plt.savefig('outlier.jpg')
plt.show()

cols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
       'pH', 'sulphates', 'alcohol']

x_outlier_detection = x
y_outlier_detection = y

mask = np.ones(len(x), dtype=bool)

for col in cols:
  Q1 = x[col].quantile(0.25)
  Q3 = x[col].quantile(0.75)

  IQR = Q3 - Q1

  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR

  mask &= (x[col] >= lower_bound) & (x[col] <= upper_bound)

x_outlier_detection = x_outlier_detection[mask]
y_outlier_detection = y_outlier_detection[mask]

x_outlier_detection.shape

y_outlier_detection.shape

fig, ax = plt.subplots(figsize=(15,15))
plt.xticks(rotation=90)
sns.boxplot(data = x_outlier_detection, ax = ax)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x_outlier_detection)

fig, ax = plt.subplots(figsize = (15,15))
# plt.xticks(rotation = 90)
sns.boxplot(data = x_scaled, ax = ax)

type(x_scaled)

type(y_outlier_detection)

x_scaled = pd.DataFrame(x_scaled, columns = x_outlier_detection.columns)

type(x_scaled)

x_scaled.columns

fig, ax = plt.subplots(figsize = (15,15))
plt.xticks(rotation = 90)
sns.boxplot(data = x_scaled, ax = ax)

q = x_scaled['total sulfur dioxide'].quantile(0.96)
mask = x_scaled['total sulfur dioxide'] < q
dataNew = x_scaled[mask]

fig, ax = plt.subplots(figsize = (15,15))
plt.xticks(rotation=90)
sns.boxplot(data = dataNew, ax = ax)
plt.savefig('boxplot.jpg')

dataNew.shape

x_scaled.shape

y_outlier_detection.value_counts()

y_outlier_detection.shape

"""Indexing Error"""

y_outlier_detection = y_outlier_detection[mask]

"""After removing outlier, dataset gets imbalance meanning their index gets misplaced.
So,to reset index we used below code
"""

x_outlier_detection.reset_index(drop=True, inplace=True)
y_outlier_detection.reset_index(drop=True, inplace=True)

y_outlier_detection.shape

dataNew.shape

y_outlier_detection = y_outlier_detection[mask]

y_outlier_detection.shape

x_outlier_detection.shape

"""**Dividing dataset into train and testing set**"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(dataNew,y_outlier_detection, test_size = 0.33, random_state=42)

x_train.shape

x_test.shape

y_train.value_counts()

"""**Imbalanced data**


1.   If we see carefully quality[6] having count 238 and quality[3,4,8...] having less number of count
2.   Therefore its called data is imbalanced. we have 3 techniques to balanced the data.


*   Oversampling
*   Undersampling
*   SMOTE




"""

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state = 42,k_neighbors=2)
x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)

y_train_resampled.value_counts()

x_train_resampled

"""**Data Modeling: Decision Tree Classifier**"""

from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(x_train_resampled,y_train_resampled)

model.predict(x_test)

from sklearn import tree
plt.figure(figsize=(15,15))
tree.plot_tree(model,filled=True)

from sklearn.metrics import accuracy_score
y_pred = model.predict(x_test)
accuracy_score(y_test,y_pred)

from sklearn.metrics import mean_squared_error
rmse = np.sqrt(mean_squared_error(y_test,y_pred))
print(rmse)

from sklearn.metrics import r2_score
r2 = r2_score(y_test,y_pred)
print(r2)

"""**Hypertuning**"""

grid_param = {
    'criterion': ['gini','entropy'],
    "n_estimators":[50,120,150,165],
    'max_depth': range(20)
}

"""**Applying GridSearchCV for hyperparameter tuning**"""

from sklearn.model_selection import GridSearchCV
grid_search = GridSearchCV(param_grid = grid_param,verbose=1,cv=10,estimator=rf)
grid_search.fit(x_train_resampled,y_train_resampled)

grid_search.best_params_

from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor
rf = RandomForestClassifier(n_estimators = 165,criterion = 'gini',max_depth = 12)
rf.fit(x_train_resampled,y_train_resampled)

rf.score(x_test,y_test)

y_pred_rf = rf.predict(x_test)

plt.figure(figsize = (15,15))
tree.plot_tree(rf.estimators_[5],filled=True)

"""**Checking R2score**"""

from sklearn.metrics import r2_score
r2_score(y_test,y_pred_rf)

"""**Classification Report**"""

from sklearn.metrics import classification_report
report = classification_report(y_test,y_pred_rf)
print(report)

"""**Model importing**"""

import pickle
pickle.dump(rf,open('wine_data.pkl',"wb"))

